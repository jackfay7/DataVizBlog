[
  {
    "objectID": "posts/BlogPost1/index.html",
    "href": "posts/BlogPost1/index.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "I am working with the wines.csv data set from the data folder provided for this course. There ae 6497 observations and 14 variables in the data set. Specifically, I am interested in alcohol and density, and how the relationship differs by type of wine. My central question is whether or not this relationship will depend on the type of wine (white or red). Before altering the data set, the density and alcohol appear to have a strong negative association (r = -0.71), yet we will examine the intricacies behind this correlation."
  },
  {
    "objectID": "posts/BlogPost1/index.html#introduction",
    "href": "posts/BlogPost1/index.html#introduction",
    "title": "Blog Post 1",
    "section": "",
    "text": "I am working with the wines.csv data set from the data folder provided for this course. There ae 6497 observations and 14 variables in the data set. Specifically, I am interested in alcohol and density, and how the relationship differs by type of wine. My central question is whether or not this relationship will depend on the type of wine (white or red). Before altering the data set, the density and alcohol appear to have a strong negative association (r = -0.71), yet we will examine the intricacies behind this correlation."
  },
  {
    "objectID": "posts/BlogPost1/index.html#primary-visualizations",
    "href": "posts/BlogPost1/index.html#primary-visualizations",
    "title": "Blog Post 1",
    "section": "Primary Visualizations",
    "text": "Primary Visualizations\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nThis initial scatterplot shows a negative relationship between density and alcohol percentage with extreme curvature. The two clear outliers (denoted by red circles), make the plot visually unappealing as the points following the common trend are clumped together on the left side.\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nHere, we see the same plot as above, yet without the two outlier data points seen previously. Visually, the plot is vastly improved and it has a much more realistic smoother that represents the trend with higher accuracy. Though we have removed the most extreme cases, we still see a moderate degree of curvature in the relationship.\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nIn this plot, the data points are colored by type (red or white) and have separate respective smoother lines. Based on this visualization, it appears that red wines have higher alcohol percentages on average than white wines. With that being said, the relationships exhibited by the slopes of the smoothers appear relatively similar. There are certainly some differences throughout the span of the plot, but generally both types trend down before flattening out just before the density of 1.000.\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nThis final plot provides the same information as the last plot, yet through separate plots to avoid any overlap. Here, we can see that the range of densities seems to be more extensive for white wines than for reds. With the faceting, we can also see that there are far more observations for white wines than red (almost 3 times as many). The smoother lines do appear more distinct in this visualization, as we see red wines having more curvature and flattening out at a lower density in comparison."
  },
  {
    "objectID": "posts/BlogPost1/index.html#conclusion-and-wrap-up",
    "href": "posts/BlogPost1/index.html#conclusion-and-wrap-up",
    "title": "Blog Post 1",
    "section": "Conclusion and Wrap-Up",
    "text": "Conclusion and Wrap-Up\nIn conclusion, it seems that there is a difference in relationship between wine density and alcohol percentage for red and white wines. First, it seems that alcohol percentage is higher on average for red wines. Additionally, the plots suggest that as density trends towards the higher end of the values, the alcohol percentage of red wines falls less drastically than for white wines. A possible flaw with this analysis is disproportionate number of cases for white wines. There were over three times as many observations for white wines as opposed to red, which presents a limitation. Additionally, having to remove outliers is not ideal, though it enhanced the visualization extensively. In the future, I would like to further delve into the differences between red and white wines. The processes of making the types of wine are different, and you would therefore anticipate different properties and relationships between components of the wine."
  },
  {
    "objectID": "posts/BlogPost1/index.html#connection-to-class-ideas",
    "href": "posts/BlogPost1/index.html#connection-to-class-ideas",
    "title": "Blog Post 1",
    "section": "Connection to Class Ideas",
    "text": "Connection to Class Ideas\nI would say my visualizations are effective for several reasons. First, the initial visualization shows the relationship between two quantitative variables with a scatterplot. The scatterplot is effective because it allows the user to see the spread, the sample size, outliers, the general trend, and more. Additionally, the use of a smoother over a regression line allows us to see the non-linear trend of the relationship. I also highlighted the outliers in the initial plot by marking them, which allowed me to improve the plot through their removal. The final plots effectively show the relationship by type of wine by coloring the points by type and providing different smoothers to show the respective trends. This plot was effective for comparisons, yet caused some overlap, which led me to produce the scatterplots that were facet wrapped around the type. In this final plot, you can see see the differences clearly and no data points are hidden."
  },
  {
    "objectID": "posts/MultiLevelModeling/index.html#level-1-covariates",
    "href": "posts/MultiLevelModeling/index.html#level-1-covariates",
    "title": "Multilevel Modeling",
    "section": "Level 1 Covariates",
    "text": "Level 1 Covariates\n\nEquipment\n\nggplot(data = lift, \n       aes(x = Equipment, y = Goodlift, fill = Equipment))+\n  geom_boxplot()+\n  labs(y = \"Goodlift Score\", title = \"Goodlift Score by Equipment Type\")\n\n\n\n# Small difference, however, very little data for single-ply\n# Most lifters use the same equipment across all lifts \n# Only 0.08 of the observations are single-ply\n\nrandom_sample &lt;- lift%&gt;%\n  slice(1:20)\n\nggplot(data = random_sample, \n       aes(x = Equipment, y = Goodlift))+\n  geom_boxplot()+\n  facet_wrap(~Name)\n\n\n\n# do not see variation from one of the equipment types among lifters\n\n\n\nTested\n\nggplot(data = lift, \n       aes(x = testedIND, y = Goodlift))+\n  geom_boxplot()\n\n\n\n# almost identical \n\nrandom_sample &lt;- lift%&gt;%\n  slice(1:100)\n\nggplot(data = random_sample, \n       aes(x = Tested, y = Goodlift))+\n  geom_boxplot()+\n  facet_wrap(~Name)\n\n\n\n# Seems to be another case where we can call this a potential level 2 covariate that will likely not be too useful \n\n\n\nMeet Country\n\nggplot(data = lift, \n       aes(x = MeetCountry, y = Goodlift))+\n  geom_boxplot()\n\n\n\n# Far too many countries to be useful under time restrictions\n# Lots of variability in each country \n\n\n\nDivision\n\nggplot(data = lift, \n       aes(x = Division, y = Goodlift))+\n  geom_boxplot()\n\n\n\n# Same case as country here \n\n\n\nEvent\n\nggplot(data = lift, \n       aes(x = Event, y = Goodlift))+\n  geom_boxplot()\n\n\n\n# Could be helpful at level 2\n\nrandom_sample &lt;- lift%&gt;%\n  slice(1:100)\n\nggplot(data = random_sample, \n       aes(x = Event, y = Goodlift))+\n  geom_boxplot()+\n  facet_wrap(~Name)\n\n\n\n\n\n\nBodyweightKg\n\n# Independence assumed \nggplot(lift,\n       aes(x=BodyweightKg,y=Goodlift)) + \n  geom_point() + \n  geom_smooth(method=\"loess\") + \n  xlab(\"BodyWeight (Kg)\") + \n  ylab(\"Goodlift\")+\n  labs(title = \"Body Weight (kg) vs. Goodlift\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Looks essentially flat\n\n\nlift.lev2 &lt;-  lift %&gt;%\n  group_by(Name) %&gt;%\n  filter(row_number() == 1) %&gt;%\n  select(Name, BodyweightKg, Goodlift)\n\nmeanbysubj &lt;- lift %&gt;% group_by(Name) %&gt;%\n  summarise(meanbysubj = mean(Goodlift, na.rm = TRUE))\n\nlift.lev2 &lt;- lift.lev2 %&gt;%\n  left_join(meanbysubj, by = \"Name\")\n\n\n# Independence not assumed\nggplot(lift.lev2,aes(x=BodyweightKg,y=meanbysubj)) + \n  geom_point() + \n  geom_smooth(method=\"loess\") + \n  xlab(\"BodyWeight\") + \n  ylab(\"Goodlift by Subject\")+\n  labs(title = \"\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Still looks flat\n\n\nlift2 &lt;- lift%&gt;%\n  slice(1:100)\n\nggplot(lift2,aes(x=cBodyweightKg,y=Goodlift)) + \n  geom_point() + \n  geom_smooth(method=\"loess\") + \n  xlab(\"Age\") + \n  ylab(\"Goodlift\")+\n  facet_wrap(~Name)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Possibly useful at level 1 \n\n\n\nBest3SquatKg\n\nggplot(data = lift, \n       aes(x = Best3SquatKg, y = Goodlift))+\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n# seems to be quite significant \n\nlift2 &lt;- lift%&gt;%\n  filter(!is.na(Best3SquatKg))%&gt;%\n  filter(!is.na(Goodlift))%&gt;%\n  slice(60:150)\n\nggplot(data = lift2, \n       aes(x = Best3SquatKg, y = Goodlift))+\n  geom_point()+\n  geom_smooth()+\n  facet_wrap(~Name)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nBest3DeadLiftKg\n\nggplot(data = lift, \n       aes(x = Best3DeadliftKg, y = Goodlift))+\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n# seems to be quite significant \n\nlift2 &lt;- lift%&gt;%\n  slice(1:150)\n\nggplot(data = lift2, \n       aes(x = Best3DeadliftKg, y = Goodlift))+\n  geom_point()+\n  geom_smooth()+\n  facet_wrap(~Name)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nBest3BenchKg\n\nggplot(data = lift, \n       aes(x = Best3BenchKg, y = Goodlift))+\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n# seems to be quite significant \n\nlift2 &lt;- lift%&gt;%\n  filter(!is.na(Best3BenchKg))%&gt;%\n  filter(!is.na(Goodlift))%&gt;%\n  slice(1:150)\n\nggplot(data = lift2, \n       aes(x = Best3BenchKg, y = Goodlift))+\n  geom_point()+\n  geom_smooth()+\n  facet_wrap(~Name)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nTotal Kg\n\nggplot(data = lift, \n       aes(x = TotalKg, y = Goodlift))+\n  geom_point()+\n  geom_smooth()\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n# seems to be quite significant \n\nlift2 &lt;- lift%&gt;%\n  slice(1:150)\n\nggplot(data = lift2, \n       aes(x = TotalKg, y = Goodlift))+\n  geom_point()+\n  geom_smooth()+\n  facet_wrap(~Name)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\nAge Class\n\nggplot(data = lift, \n       aes(x = AgeClass, y = Goodlift))+\n  geom_boxplot()\n\n\n\n# Looks to be useful \n\n\n\nSex\n\nggplot(data = lift, \n       aes(x = Sex, y = Goodlift))+\n  geom_boxplot()\n\n\n\n# use sex \n\n\n\nAge\n\n# Exploring Age vs. Goodlift \n\nlift&lt;-lift%&gt;%\n  mutate(age_centered = (Age - mean(Age, na.rm = TRUE)))\n\n# Independence assumed \nggplot(lift,aes(x=age_centered,y=Goodlift)) + \n  geom_point() + \n  geom_smooth(method=\"loess\") + \n  xlab(\"Age\") + \n  ylab(\"Goodlift\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nlift.lev2 &lt;-  lift %&gt;%\n  group_by(Name) %&gt;%\n  filter(row_number() == 1) %&gt;%\n  select(Name, age_centered, Goodlift)\n\nmeanbysubj &lt;- lift %&gt;% group_by(Name) %&gt;%\n  summarise(meanbysubj = mean(Goodlift, na.rm = TRUE))\n\nlift.lev2 &lt;- lift.lev2 %&gt;%\n  left_join(meanbysubj, by = \"Name\")\n\n\n# Independence not assumed\nggplot(lift.lev2,aes(x=age_centered,y=meanbysubj)) + \n  geom_point() + \n  geom_smooth(method=\"loess\") + \n  xlab(\"Age\") + \n  ylab(\"Goodlift by Subject\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Do not feel confortable putting age in due to the AgeClass gap"
  },
  {
    "objectID": "posts/BlogPost3/index.html",
    "href": "posts/BlogPost3/index.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "The data set I am working with for this post consists of 10000 individuals and whether their credit card has defaulted or not. The variables I am interested in are card balance, income, and whether the credit card holder is a student. My goal is to model and visualize probability of defaulting by using logistic regression. An important quality of the data to note is that nearly 97% of the cases do not default. The data set is publicly available on Kaggle and can be found through the link below.\nLink: Default Dataset\n\n\n\n\n# A tibble: 2 × 2\n  default total\n  &lt;chr&gt;   &lt;int&gt;\n1 No       9667\n2 Yes       333"
  },
  {
    "objectID": "posts/BlogPost3/index.html#introduction",
    "href": "posts/BlogPost3/index.html#introduction",
    "title": "Blog Post 3",
    "section": "",
    "text": "The data set I am working with for this post consists of 10000 individuals and whether their credit card has defaulted or not. The variables I am interested in are card balance, income, and whether the credit card holder is a student. My goal is to model and visualize probability of defaulting by using logistic regression. An important quality of the data to note is that nearly 97% of the cases do not default. The data set is publicly available on Kaggle and can be found through the link below.\nLink: Default Dataset\n\n\n\n\n# A tibble: 2 × 2\n  default total\n  &lt;chr&gt;   &lt;int&gt;\n1 No       9667\n2 Yes       333"
  },
  {
    "objectID": "posts/BlogPost3/index.html#modeling-default",
    "href": "posts/BlogPost3/index.html#modeling-default",
    "title": "Blog Post 3",
    "section": "Modeling Default",
    "text": "Modeling Default\n\nmod &lt;- glm(default ~ balance + student, data = credit,\n                     family = \"binomial\")\nsummary(mod)\n\n\nCall:\nglm(formula = default ~ balance + student, family = \"binomial\", \n    data = credit)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.075e+01  3.692e-01 -29.116  &lt; 2e-16 ***\nbalance      5.738e-03  2.318e-04  24.750  &lt; 2e-16 ***\nstudentYes  -7.149e-01  1.475e-01  -4.846 1.26e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2920.6  on 9999  degrees of freedom\nResidual deviance: 1571.7  on 9997  degrees of freedom\nAIC: 1577.7\n\nNumber of Fisher Scoring iterations: 8\n\n\n\ngrid &lt;- credit |&gt;\n  data_grid(\n    balance = seq_range(balance, n = 60),\n    student = c(\"Yes\", \"No\")\n  ) \n\naug &lt;- augment(mod, newdata = grid,\n                    se_fit = TRUE)\n\naug &lt;- aug|&gt;\n  mutate(.lower = .fitted - .se.fit,\n         .upper = .fitted + .se.fit)\n\n\n\n# obtaining sample to avoid overlap in following geom_rug()\ndefault_yes &lt;- credit|&gt;\n  filter(default == 1)|&gt;\n  sample_n(size = 50, replace = F)\n\n\ndefault_no &lt;- credit|&gt;\n  filter(default == 0)|&gt;\n  sample_n(size = 50, replace = F)"
  },
  {
    "objectID": "posts/BlogPost3/index.html#log-odds-visualization",
    "href": "posts/BlogPost3/index.html#log-odds-visualization",
    "title": "Blog Post 3",
    "section": "Log Odds Visualization",
    "text": "Log Odds Visualization\n\nggplot(data = aug, \n       aes(x = balance, y = .fitted, group = student))+\n  geom_line(aes(color = student), size = 0.9)+\n  geom_ribbon(data = aug, aes(y = .fitted,\n                                  ymin = .lower,\n                                  ymax = .upper, color = student, fill = student), \n              alpha = 0.3)+\n  geom_rug(data = default_yes, sides = \"t\", aes(y = default), color = \"tomato\")+\n  geom_rug(data = default_no, sides = \"b\", aes(y = default), color = \"darkturquoise\")+\n  theme_minimal()+\n  labs(x = \"Card Balance\", y = \"Predicted Log-Odds\", title = \"Model Predictions\", caption = \"*tick marks reflect actual points\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nThis plot displays the relationship between the predicted log odds of the model and account balance. As denoted by the key, there are two lines which exhibit the impact of our student variable. Evidently, non-students have increased log odds for defaulting in comparison to students. This is congruent with our negative model coefficient for studentYes, which reflects a lower probability of defaulting. The red marks on the bottom show cases where the card holder did not default, while the upper blue marks display cases that did default. It is also important to note that as card balance increases, the log odds of defaulting increase accordingly.\n\naug2 &lt;- aug|&gt;\n  mutate(.prob = (exp(.fitted)) / (1 + exp(.fitted)), \n         .lowerprob = (exp(.lower)) / (1 + exp(.lower)),\n         .upperprob = (exp(.upper)) / (1 + exp(.upper)))"
  },
  {
    "objectID": "posts/BlogPost3/index.html#probability-visualization",
    "href": "posts/BlogPost3/index.html#probability-visualization",
    "title": "Blog Post 3",
    "section": "Probability Visualization",
    "text": "Probability Visualization\n\nggplot(data = aug2, \n       aes(x = balance, y = .prob, group = student))+\n  geom_line(aes(color = student), size = 0.9)+\n  geom_ribbon(data = aug2, aes(y = .prob,\n                                  ymin = .lowerprob,\n                                  ymax = .upperprob, color = student, fill = student), \n              alpha = 0.3)+\n  geom_rug(data = default_yes, sides = \"t\", aes(y = default), color = \"tomato\")+\n  geom_rug(data = default_no, sides = \"b\", aes(y = default), color = \"darkturquoise\")+\n  theme_minimal()+\n  labs(x = \"Card Balance\", y = \"Predicted Probabilities\", title = \"Model Predictions\", caption = \"*tick marks reflect actual points\")\n\n\n\n\nThis visualization is identical to the last, yet now the log odds on the y-axis have been converted to display the predicted probability of defaulting. We again see that as balance increases, the probability of defaulting increases, while students have a reduced chance of defaulting."
  },
  {
    "objectID": "posts/BlogPost3/index.html#conclusion-and-wrap-up",
    "href": "posts/BlogPost3/index.html#conclusion-and-wrap-up",
    "title": "Blog Post 3",
    "section": "Conclusion and Wrap-Up",
    "text": "Conclusion and Wrap-Up\nIn conclusion, the class imbalance of the default target variable is a limitation to this analysis. This may lead to model bias, as the model is likely to favor non-defaulting accounts because, as said before, nearly 97% of cases did not in fact default. Additional interest with the analysis pertain to the oddities of the our student variable. My common sense would lead me to believe that students would be more likely to default but this was not the case, as shown by the model summary and the visualization. In the future, I would certainly further investigate the impacts of being a student on probability of defaulting, and overall financial well being. Lastly, I think that an expanded data set with more metrics would certainly add to the capabilities of analysis."
  },
  {
    "objectID": "posts/BlogPost3/index.html#connection-to-class-ideas",
    "href": "posts/BlogPost3/index.html#connection-to-class-ideas",
    "title": "Blog Post 3",
    "section": "Connection to Class Ideas",
    "text": "Connection to Class Ideas\nI would argue that this visualization is effective because it displays all of the components of the logistic regression model which I built to predict defaults. The process of creating the model, using the grid feature to make predictions at different values of our predictors, and displaying the resulting model allows viewers to understand precisely how the model is gauging probability for cases. Additionally, the use of the ribbon helps to display model uncertainty in terms of standard error."
  },
  {
    "objectID": "posts/BlogPost3/index.html#adding-income-to-the-model",
    "href": "posts/BlogPost3/index.html#adding-income-to-the-model",
    "title": "Blog Post 3",
    "section": "Adding income to the Model",
    "text": "Adding income to the Model\n\nmod2 &lt;- glm(default ~ balance + income + student, data = credit,\n                     family = \"binomial\")\n\ngrid2 &lt;- credit |&gt;\n  data_grid(\n    balance = seq_range(balance, n = 60),\n    income = seq_range(income, n = 4, pretty = T),\n    student = c(\"Yes\", \"No\")\n  ) \n\naug3 &lt;- augment(mod2, newdata = grid2,\n                    se_fit = TRUE)|&gt;\n  mutate(.lower = .fitted - .se.fit,\n         .upper = .fitted + .se.fit)\n\n\n\nggplot(data = aug3, \n       aes(x = balance, y = .fitted, color = factor(income), fill = factor(income)))+\n  geom_smooth(se = T)+\n  geom_rug(data = default_yes, sides = \"t\", aes(y = default), color = \"tomato\")+\n  geom_rug(data = default_no, sides = \"b\", aes(y = default), color = \"darkturquoise\")+\n  facet_wrap(~student)+\n  theme_minimal()+\n  labs(x = \"Card Balance\", y = \"Predicted Log-Odds\", title = \"Model Predictions\", caption = \"*tick marks reflect actual points\", color = \"Income\")+\n  guides(fill = \"none\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nIn the plot above, we see that income has little to no effect in predicting probability of default. The lines at various values of income do not differ in intecept by very much, meaning it should likely not be included in the final model.\n\nsummary(mod2)\n\n\nCall:\nglm(formula = default ~ balance + income + student, family = \"binomial\", \n    data = credit)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.087e+01  4.923e-01 -22.080  &lt; 2e-16 ***\nbalance      5.737e-03  2.319e-04  24.738  &lt; 2e-16 ***\nincome       3.033e-06  8.203e-06   0.370  0.71152    \nstudentYes  -6.468e-01  2.363e-01  -2.738  0.00619 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2920.6  on 9999  degrees of freedom\nResidual deviance: 1571.5  on 9996  degrees of freedom\nAIC: 1579.5\n\nNumber of Fisher Scoring iterations: 8\n\n\nExamining the summary of the model output, our findings from the plot above are reflects by the small t-value associated with income. Additionally, the AIC is lower in the first model, confirming that income is not useful in the model for predicting default probability."
  },
  {
    "objectID": "posts/BlogPost2/index.html",
    "href": "posts/BlogPost2/index.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "The data set that I am using for this post is titled life_expectancy.csv, and comes from the GitHub repository tidytuesday. It is an update to a former global life expectancy data set and the source is from United Nations World Population Prospects (2022); Human Mortality Database (2023); Zijdeman, Richard and Filipa Ribeira da Silva (2015), Life Expectancy at Birth (Total); Riley, J.C. (2005), Estimates of Regional and Global Life Expectancy 1800-2001, Population and Development Review, 31: 537-543. Minor processing by Our World in Data. There are 20755 total observations in the data set, and I will be looking at life expectancy by country and throughout time. I joined a second basic data set to make a larger data set that had a variable to group countries by continents. My question of interest is how life expectancy has changed by continent since 1850. The first plot will just show the life expectancy of each country in 2021 in map format, before I switch the focus to change over time.\nLink: https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-12-05/readme.md\n\n\nRows: 20755 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Entity, Code\ndbl (2): Year, LifeExpectancy\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 286 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Country, Continent\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThis first plot displays the average life expectancy of each country in 2021, with lighter colors representing higher life expectancy. It appears that Australia may be the highest, with countries such as Canada coming in close.\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nThis plot focuses on the change in life expectancy over time and groups the countries into the continents to which they respectively belong. The blue curve represents the average for the continent with individual countries in the background. It seems that Europe and Africa have had a relatively linear progression in life expectancy since 1850, especially compared to the rest. The rest seem to display a cubic relationship over tine that is peaking with modern times. It is important to note that the range of available data varies by continent, with some having collected data before others."
  },
  {
    "objectID": "posts/BlogPost2/index.html#introduction",
    "href": "posts/BlogPost2/index.html#introduction",
    "title": "Blog Post 2",
    "section": "",
    "text": "The data set that I am using for this post is titled life_expectancy.csv, and comes from the GitHub repository tidytuesday. It is an update to a former global life expectancy data set and the source is from United Nations World Population Prospects (2022); Human Mortality Database (2023); Zijdeman, Richard and Filipa Ribeira da Silva (2015), Life Expectancy at Birth (Total); Riley, J.C. (2005), Estimates of Regional and Global Life Expectancy 1800-2001, Population and Development Review, 31: 537-543. Minor processing by Our World in Data. There are 20755 total observations in the data set, and I will be looking at life expectancy by country and throughout time. I joined a second basic data set to make a larger data set that had a variable to group countries by continents. My question of interest is how life expectancy has changed by continent since 1850. The first plot will just show the life expectancy of each country in 2021 in map format, before I switch the focus to change over time.\nLink: https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-12-05/readme.md\n\n\nRows: 20755 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Entity, Code\ndbl (2): Year, LifeExpectancy\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 286 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Country, Continent\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nThis first plot displays the average life expectancy of each country in 2021, with lighter colors representing higher life expectancy. It appears that Australia may be the highest, with countries such as Canada coming in close.\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nThis plot focuses on the change in life expectancy over time and groups the countries into the continents to which they respectively belong. The blue curve represents the average for the continent with individual countries in the background. It seems that Europe and Africa have had a relatively linear progression in life expectancy since 1850, especially compared to the rest. The rest seem to display a cubic relationship over tine that is peaking with modern times. It is important to note that the range of available data varies by continent, with some having collected data before others."
  },
  {
    "objectID": "posts/BlogPost2/index.html#conclusion-and-wrap-up",
    "href": "posts/BlogPost2/index.html#conclusion-and-wrap-up",
    "title": "Blog Post 2",
    "section": "Conclusion and Wrap-Up",
    "text": "Conclusion and Wrap-Up\nOne of the flaws with the approach of the first plot is that you cannot see change over time in life expectancy for these countries. The second plot does a better job of accomplishing this, yet there are so many countries in each continent it is hard to look at the lines behind the average. I think moving farward, it would be better to subset the data to include fewer countries or just focus on one continent."
  },
  {
    "objectID": "posts/BlogPost2/index.html#connection-to-class-ideas",
    "href": "posts/BlogPost2/index.html#connection-to-class-ideas",
    "title": "Blog Post 2",
    "section": "Connection to Class Ideas",
    "text": "Connection to Class Ideas\nI would say my visualizations are effective because the first one just shows the data for a specific year on a map. The map allows you to compare the values geographically, however, if you are trying to show change over time it does not make as much sense. For that reason, I switched my approach and showed how average life expectancys by continent change throughout time. You cannot see the individual countries as well as in the first plot, but it conveys far more information."
  },
  {
    "objectID": "posts/PoissonModeling/index.html",
    "href": "posts/PoissonModeling/index.html",
    "title": "Poisson Regression Modeling",
    "section": "",
    "text": "Introduction\nThe goal of this project is to conduct exploratory analysis on the data set to determine useful predictors for a poisson regression model. Additionally, I will examine the Poisson model fit and any potential impacts caused by overdispersion.\n\nData\nData are available from a study on horseshoe crabs. Female horseshoe crabs often have male crabs attached to a female’s nest known as satellites. One objective of the study was to determine which characteristics of the female were associated with the number of satellites. Of particular interest is the relationship between the width of the female carapace and satellites.\nThe data can be found in crab.csv. It includes: - NumStat = number of satellites - Width = carapace width (cm) - Weight = weight (kg) - Spine = spine condition (1 = both good, 2 = one worn or broken, 3 = both worn or broken) - Color = (2 = light medium, 3 = medium, 4 = dark medium, 5 = dark)\n\n\n\nPart 1: Exploratory Data Analysis\n\nggplot(crab, aes(x = Satellite)) + \n  geom_histogram(binwidth = .25) + \n  xlab(\"Number of Satellites\") +\n  ylab(\"Count of Crabs\")\n\n\n\nmean(crab$Satellite)\n\n[1] 2.919075\n\nvar(crab$Satellite)\n\n[1] 9.912018\n\n\nIt seems that the mode count of satellites is zero. The variance of our response of carapace satellites is significantly higher than the mean which indicates we will likely have an issue with the mean = variance assumption.\n\nExploring by Width\n\nsumStats &lt;- crab |&gt;\n  group_by(Width = ntile(Width, 15)) |&gt; \n  summarise(n = n(),\n            mnSatellite = mean(Satellite),\n            varSatellite = var(Satellite), \n            logmnSatellite = log(Satellite)\n            )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Width'. You can override using the\n`.groups` argument.\n\nggplot(sumStats, aes(x = Width, y = logmnSatellite)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", size = 1.5) +\n  xlab(\"Width of the crab\") +\n  ylab(\"Log of the empirical mean number of satellites\") \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 62 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\nThere does not appear to be much of a relationship between width of crab and the log mean number of satellites. The line is fairly flat but appears to be linear.\n\n\nExploring by Width and Color\n\nsumStats &lt;- crab |&gt;\n  group_by(Width = ntile(Width, 17), Color) |&gt; \n  summarise(n = n(),\n            mnSatellite = mean(Satellite),\n            varSatellite = var(Satellite), \n            logmnSatellite = log(Satellite)\n            )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Width', 'Color'. You can override using\nthe `.groups` argument.\n\nggplot(sumStats, aes(x = Width, y = logmnSatellite, color = Color)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 62 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\nThere seems to be a significant difference in the trends among the various colors. The log mean number of satellites seems to be different for different colors as the weight increases. None of the colors share a consistent trend throughout the data.\n\n\nExploring by Width and Spine\n\nsumStats &lt;- crab |&gt;\n  group_by(Width = ntile(Width, 15), Spine) |&gt; \n  summarise(n = n(),\n            mnSatellite = mean(Satellite),\n            varSatellite = var(Satellite), \n            logmnSatellite = log(Satellite)\n            )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Width', 'Spine'. You can override using\nthe `.groups` argument.\n\nggplot(sumStats, aes(x = Width, y = logmnSatellite, color = Spine)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 62 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 5\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 2\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 3.6117e-17\n\n\n\n\n\nIt seems that the trends are very different when grouped by spine conditions. This indicates that there is likely an interaction between the width and the spine condition, in relation the the log mean number of satellites. I would infer that both spine condition and color play roles in the number of satellites.\n\n\nExploring by Weight\n\nsumStats &lt;- crab |&gt;\n  group_by(Weight = ntile(Weight, 17)) |&gt; \n  summarise(n = n(),\n            mnSatellite = mean(Satellite),\n            varSatellite = var(Satellite), \n            logmnSatellite = log(Satellite)\n            )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Weight'. You can override using the\n`.groups` argument.\n\nggplot(sumStats, aes(x = Weight, y = logmnSatellite)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", size = 1.5) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 62 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\nIt seems that weight has a relatively flat and linear relationship with log mean number of satellites. It seems to follow a very similar trend to width, which leads me to believe that width and weight are highly correlated.\n\n\nExploring by Weight and Color\n\nsumStats &lt;- crab |&gt;\n  group_by(Weight = ntile(Weight, 17), Color) |&gt; \n  summarise(n = n(),\n            mnSatellite = mean(Satellite),\n            varSatellite = var(Satellite), \n            logmnSatellite = log(Satellite)\n            )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Weight', 'Color'. You can override using\nthe `.groups` argument.\n\nggplot(sumStats, aes(x = Weight, y = logmnSatellite, color = Color)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 62 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\nIt seems that the intercepts are different for colors 1-4, but they share fairly similar trends. For dark color (5), there is a much more distinct trend that does not seem to be similar to the others. I think color should be used in the model based on our findings.\n\n\nExploring by Weight and Spine\n\nsumStats &lt;- crab |&gt;\n  group_by(Weight = ntile(Weight, 17), Spine) |&gt; \n  summarise(n = n(),\n            mnSatellite = mean(Satellite),\n            varSatellite = var(Satellite), \n            logmnSatellite = log(Satellite)\n            )\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Weight', 'Spine'. You can override using\nthe `.groups` argument.\n\nggplot(sumStats, aes(x = Weight, y = logmnSatellite, color = Spine)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 62 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 3.935\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 4.065\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 1.1285e-16\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 9\n\n\n\n\n\nThe trends appear to deviate from each other yet not a durastically as seen in the previous plots. There is likely a chance that spine will play a roll in predicted satellites, yet it is harder to see differences when we are examining the relationship by weight.\n\nExploring relationship between Color and Spine\n\nggplot(crab, aes(x=Color, y=Satellite, fill=Spine)) + \n  geom_boxplot() \n\n\n\n\nIt seems that there is no consistent pattern by color, as the number of satellites for each color varies by spine condition. This could suggest an interaction between the variables, yet we also have NA values for some spine conditions which could be problematic.\n\n\nWidth vs weight\n\nggplot(data = crab,\n       aes(x = Weight, y = Width))+\n  geom_point()\n\n\n\ncor(crab$Weight, crab$Width)\n\n[1] 0.8868715\n\n\nIt seems that Width and Weight have a positive linear relationship. Due to the high correlation between the two variables, I would not include weight in the model. Especially because we are specifically interested in the relationship between between the width of the female carapace and satellites.\n\nmod1 = glm(Satellite ~ Width , family= \"poisson\" , data=crab)\nsummary(mod1)\n\n\nCall:\nglm(formula = Satellite ~ Width, family = \"poisson\", data = crab)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.30476    0.54224  -6.095  1.1e-09 ***\nWidth        0.16405    0.01997   8.216  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 632.79  on 172  degrees of freedom\nResidual deviance: 567.88  on 171  degrees of freedom\nAIC: 927.18\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nmod2 = glm(Satellite ~ Width + Color, family= \"poisson\" , data=crab)\nsummary(mod2)\n\n\nCall:\nglm(formula = Satellite ~ Width + Color, family = \"poisson\", \n    data = crab)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.65004    0.58802  -4.507 6.58e-06 ***\nWidth        0.14934    0.02084   7.166 7.73e-13 ***\nColor3      -0.19969    0.15364  -1.300   0.1937    \nColor4      -0.43636    0.17636  -2.474   0.0133 *  \nColor5      -0.44736    0.20912  -2.139   0.0324 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 632.79  on 172  degrees of freedom\nResidual deviance: 559.34  on 168  degrees of freedom\nAIC: 924.64\n\nNumber of Fisher Scoring iterations: 6\n\n\nNested Likelihood Ratio Test X^2 = 567.88-559.34 = 8.54 df = 3\n\npchisq(8.54, df = 3, lower.tail = FALSE)\n\n[1] 0.0360753\n\n\n0.036 Evidence that color improves the model.\n\nmod3 = glm(Satellite ~ Width + Color + Spine  , family= \"poisson\" , data=crab)\nsummary(mod3)\n\n\nCall:\nglm(formula = Satellite ~ Width + Color + Spine, family = \"poisson\", \n    data = crab)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.54385    0.62426  -4.075 4.60e-05 ***\nWidth        0.14596    0.02189   6.669 2.58e-11 ***\nColor3      -0.22158    0.16789  -1.320   0.1869    \nColor4      -0.46036    0.19554  -2.354   0.0186 *  \nColor5      -0.48544    0.22824  -2.127   0.0334 *  \nSpine2      -0.13879    0.21269  -0.653   0.5141    \nSpine3       0.02363    0.11729   0.201   0.8403    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 632.79  on 172  degrees of freedom\nResidual deviance: 558.63  on 166  degrees of freedom\nAIC: 927.93\n\nNumber of Fisher Scoring iterations: 6\n\n\nNested Likelihood ratio test against mod1 X^2 = 567.88-558.63 = 9.25 df = 5\n\npchisq(9.25, 5, lower.tail = FALSE)\n\n[1] 0.09949846\n\n\nWith a p-value of 0.099, this model is not better than one that just uses width.\nNested Likelihood ratio test against mod2 X^2 = 559.34-558.63 = 0.71 df = 2\n\npchisq(0.71, 2, lower.tail = FALSE)\n\n[1] 0.7011734\n\n\nWith a p-value of 0.71, there is no evidence that adding the spine term improves the model.\n\n# FINAL MODEL\nmod4 = glm(Satellite ~ Color + Width + Width:Color, family= \"poisson\" , data=crab)\nsummary(mod4)\n\n\nCall:\nglm(formula = Satellite ~ Color + Width + Width:Color, family = \"poisson\", \n    data = crab)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)    3.57144    2.46299   1.450  0.14705   \nColor3        -6.13346    2.55488  -2.401  0.01636 * \nColor4        -8.51524    2.83682  -3.002  0.00268 **\nColor5       -10.54353    3.31180  -3.184  0.00145 **\nWidth         -0.08057    0.09187  -0.877  0.38046   \nColor3:Width   0.21942    0.09513   2.306  0.02108 * \nColor4:Width   0.30017    0.10598   2.832  0.00462 **\nColor5:Width   0.37883    0.12457   3.041  0.00236 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 632.79  on 172  degrees of freedom\nResidual deviance: 547.57  on 165  degrees of freedom\nAIC: 918.86\n\nNumber of Fisher Scoring iterations: 6\n\nAIC(mod4)\n\n[1] 918.8643\n\n\nNested Likelihood ratio test against mod2 X^2 = 559.34-547.57 = 11.77 df = 3\n\npchisq(11.77, df = 3, lower.tail = FALSE)\n\n[1] 0.008214043\n\n\nWith a p-value of 0.008, there is strong evidence that the interaction term with color improves the model.\n567.88-547.57 = 20.31 df = 6\n\npchisq(20.31, 6, lower.tail = FALSE)\n\n[1] 0.002438512\n\n\nWith a p-value of 0.002, there is clear evidence that this model with the color interaction term is better than just using width.\n\n\n\n\nPart 2\n\n1.\n\nsummary(mod4)\n\n\nCall:\nglm(formula = Satellite ~ Color + Width + Width:Color, family = \"poisson\", \n    data = crab)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)    3.57144    2.46299   1.450  0.14705   \nColor3        -6.13346    2.55488  -2.401  0.01636 * \nColor4        -8.51524    2.83682  -3.002  0.00268 **\nColor5       -10.54353    3.31180  -3.184  0.00145 **\nWidth         -0.08057    0.09187  -0.877  0.38046   \nColor3:Width   0.21942    0.09513   2.306  0.02108 * \nColor4:Width   0.30017    0.10598   2.832  0.00462 **\nColor5:Width   0.37883    0.12457   3.041  0.00236 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 632.79  on 172  degrees of freedom\nResidual deviance: 547.57  on 165  degrees of freedom\nAIC: 918.86\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n2.\nt.s. = 632.79-547.57 = 85.22 df = 7\n\npchisq(85.22, 7, lower.tail = FALSE)\n\n[1] 1.181768e-15\n\n\nThere is clear evidence that the model is useful(X^2 = 85.22, df = 7, p-value = 0).\n\n\n3.\n\nexp(-0.08057)-1 \n\n[1] -0.07740968\n\n\nA one centimeter increase in carapace width is associated with a 7.7% increase in the mean number of satellites. The carapace width term in the model is not significant, however, it is necessary for the model. Though width itself will not significantly impact the predicted mean number of satellites, the interaction terms play an important role in adjusting for color.\n\n\n4.\n\npchisq(547.57, 165, lower.tail = FALSE)\n\n[1] 1.508815e-42\n\n\nThere is clear evidence that the model has significant lack of fit (X^2 = 547.57, p-value = 0).\n\n\n\nPart 3\n\nDHARMa::testDispersion(mod4)\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 2.9366, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nmod5 &lt;- glm.nb(Satellite ~ Color + Width + Width:Color, data = crab)\nsummary(mod5)\n\n\nCall:\nglm.nb(formula = Satellite ~ Color + Width + Width:Color, data = crab, \n    init.theta = 0.9575041922, link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)   3.78848    5.55556   0.682    0.495\nColor3       -7.03202    5.75422  -1.222    0.222\nColor4       -9.20707    6.12183  -1.504    0.133\nColor5       -9.35229    6.78019  -1.379    0.168\nWidth        -0.08865    0.20600  -0.430    0.667\nColor3:Width  0.25270    0.21337   1.184    0.236\nColor4:Width  0.32642    0.22835   1.429    0.153\nColor5:Width  0.33242    0.25582   1.299    0.194\n\n(Dispersion parameter for Negative Binomial(0.9575) family taken to be 1)\n\n    Null deviance: 219.74  on 172  degrees of freedom\nResidual deviance: 196.92  on 165  degrees of freedom\nAIC: 764.52\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.958 \n          Std. Err.:  0.175 \n\n 2 x log-likelihood:  -746.518 \n\n\nThere certainly was a significant problem with overdispersion in the model, as indicated by both the lack of fit test and the DHARMa package ‘testDispersion’ method. I used a negative binomial model to adjust for this overdispersion, which appeared to work effectively in that regard. While the adjustment reduced the overdispersion, the significance of all predictors dropped substantially. Despite that, there is still evidence that the model is useful (X^2 = 22.82, p-value = 0.0018).\nOverall Model Utility\n\nts &lt;- 219.74 - 196.92\ndf &lt;- 7 \n\npchisq(ts, df, lower.tail = FALSE)\n\n[1] 0.001832075"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataVizBlog",
    "section": "",
    "text": "Poisson Regression Modeling\n\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nJack Fay\n\n\n\n\n\n\n  \n\n\n\n\nMultilevel Modeling\n\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nJack Fay\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 3\n\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nJack Fay\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 2\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nJack Fay\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 1\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nJack Fay\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog is a GitHub site that holds personal projects on data analysis. Each blog post features a separate topic of interest with a supporting visualization."
  }
]